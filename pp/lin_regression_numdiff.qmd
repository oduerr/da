---
title: Linear Regression with probabilistic programming
format: md
editor: visual
md_document:
    variant: markdown_github
---

This notebook shows how to do a simple linear regression using stochastic gradient descent. You will see that you just need to define the likelihood of the model and the rest is done automatically. We will first use the `numDeriv` package to calculate the gradient and use the high level probabilistic programming language Stan. 

## Data Generation
```{r, name='data'}
# Generating data from a linear regression model
set.seed(1)
x = seq(0,5, length.out = 50)
y = rnorm(50, mean = 2 * x + 1, sd = 1)
plot(x,y)
lines(x, 2 * x + 1, xlab = "x", ylab = "y")
```

## Definition of the likelihood

The negative log-likelihood of the linear regression model given the data, can be calculated as follows:
```{r, name='nll'}
nll <- function(params, x, y) {
  beta_0 <- params[1]
  beta_1 <- params[2]
  sigma <- params[3]
  y_hat <- beta_0 + beta_1 * x 
  nll <- -mean(dnorm(y, mean = y_hat, sd = sigma, log = TRUE))
  return(nll)
}
nll(c(0,1,1), x, y) #beta_0 = 0, beta_1 = 1, sigma = 1 ==> ~8.81
```

## Side Track Automatic Differentiation
Integration is hard, but differentiation became easy with computers. In the following we show how to calculate the gradient of a function using the `numDeriv` package. The `numDeriv` package uses numerical differentiation to calculate the gradient. 
```{r, name='autograd'}
library(numDeriv)
x2 = function(x) x^2
grad(x2, 2) #derivative of x^2 w.r.t x at x=2

#(ùë•+ùë¶)‚ãÖùëß
f = function(p) (p[1] + p[2]) * p[3]
grad(f, c(-2,5,-4)) #derivative of (x+y)*z w.r.t x,y,z at x=1, y=2, z=3

f = function(p) {
  res = 0
  for (i in 1:10){
    if (i %% 2 == 0)
      res = res + p[1] * i
    else
      res = res + p[2] * i
  }
  res = res + p[3]
  return(res)
}
grad(f, c(-2,5,-4)) #30 25  1

```

## Calculation of the gradient of the NLL
Note that it is possible to calculate the gradient of the negative log-likelihood using the `numDeriv` package. The gradient is calculated as follows:

```{r}
p = c(0,1,1)
grad_est <- grad(func = function(p) nll(p, x, y), p) #derivative of nll w.r.t p
grad_est
```

## Doing gradient descent
Let us now do a simple gradient descent. We start with some initial values for the parameters and then iteratively update the parameters in the direction of the negative gradient. 

```{r}
p = c(1,1,1) #Initial values for the parameters
lr = 0.01 #Definition of the learning rate
for (i in 1:1000) {
  if (i == 1 | i %% 100 == 0)
    print(c(i, p, nll(p, x, y)))
  grad_est <- grad(func = function(p) nll(p, x, y), x = p)
  p = p - lr * grad_est #Update the parameters
}
print(p)
```

After about 1000 iterations the parameters are close to their optimal values. We can use the ultra fast optimized `lm` method to find the maximum likelihood estimates.

```{r} 
lm(y ~ x)$coefficients
logLik(lm(y ~ x)) #log-likelihood of the lm model (sum and not the mean)
```

## Using stan
We can also use the `cmdrstan` package to do the optimization. Here is the stan code

```{r, warning=FALSE, message=FALSE, eval=TRUE}
#| class-output: stan
#| echo: false
cat(readLines("lr.stan"), sep = "\n")
```

Especially with `cmdrstan` it is a good practice to have the stan code in a separate file. This makes it easier to debug and to work with the code. Further, the models are then cached.

```{r, warning=FALSE, message=FALSE}
library(cmdstanr)
stan_data = list(N = length(x), x = x, y = y)
mod = cmdstan_model('lr.stan')
mod$optimize(data = stan_data)
```
### The target += syntax
The `target +=` is used to add the log-likelihood to the target.\footnote{In Bayesian context the `target` is the log-posterior that is the log-likelihood plus the log-prior. Here it is just the log-likelihood} The `target` is a global variable that is used to store the quantity to minimize. The `target` is then used to calculate the gradients and the Hessian. 

### Alternative model syntax
Instead of the of the loop we can have a vector. In `target +=` syntax, we can also use the `~` syntax. So all 3 model definiton yield the same result for the coefficients.

```{eval=FALSE}
//Loop slowest
model {
    for (i in 1:N) {
        target += normal_lpdf(y[i] | beta_1 * x[i] + beta_0, sigma);
    }
}

//Vectorized
model{
  target += normal_lpdf(y | beta_1 * x + beta_0, sigma);
}

// ~ syntax
model{
  y ~ normal(beta_1 * x + beta_0, sigma);
}
```

Note that the `~` syntax is more readable and usually prefered. A little subtlety is using the `~` syntax constants in the density like the $\sqrt(2 \pi)$ are not included. This is not a problem, because the constants are not needed for optimization but gives different `lp__` values. So don't be surprised if the `lp__` values are different.




