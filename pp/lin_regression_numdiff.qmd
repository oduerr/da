---
title: Linear Regression (SGD)
format: md
editor: visual
md_document:
    variant: markdown_github
---

This notebook shows how to do a simple linear regression using s,tochastic gradient descent. 
We will just define the likelihood of the linear regression model, the rest is done automatically.


```{r, name='data'}
set.seed(1)
x = seq(0,5, length.out = 50)
y = rnorm(50, mean = 2 * x + 1, sd = 1)
plot(x,y)
lines(x, 2 * x + 1, xlab = "x", ylab = "y")
```

## Definition of the likelihood

The negative log-likelihood of the linear regression model given the data, can be calculated as follows:
```{r}
nll <- function(params, x, y) {
  beta_0 <- params[1]
  beta_1 <- params[2]
  sigma <- params[3]
  y_hat <- beta_0 + beta_1 * x 
  nll <- -mean(dnorm(y, mean = y_hat, sd = sigma, log = TRUE))
  return(nll)
}
nll(c(0,1,1), x, y) #beta_0 = 0, beta_1 = 1, sigma = 1 ==> ~8.81
```

## Side Track Automatic Differentiation
Integration is hard, but differentiation became easy with computers‚Ä¶ 
```{r}
library(numDeriv)
x2 = function(x) x^2
grad(x2, 2) #derivative of x^2 w.r.t x at x=2

#(ùë•+ùë¶)‚ãÖùëß
f = function(p) (p[1] + p[2]) * p[3]
grad(f, c(-2,5,-4)) #derivative of (x+y)*z w.r.t x,y,z at x=1, y=2, z=3

f = function(p) {
  res = 0
  for (i in 1:10){
    if (i %% 2 == 0)
      res = res + p[1] * i
    else
      res = res + p[2] * i
  }
  res = res + p[3]
  return(res)
}
grad(f, c(-2,5,-4)) #30 25  1

```

## Calculation of the gradient
Note that it is possible to calculate the gradient of the negative log-likelihood of a function using the `numDeriv` package. The gradient is calculated as follows:

```{r}
p = c(0,1,1)
grad_est <- grad(func = function(p) nll(p, x, y), p) #derivative of nll w.r.t p
grad_est
```

## Doing gradient descent
Let us now do a simple gradient descent. We start with some initial values for the parameters and then iteratively update the parameters in the direction of the negative gradient. 

```{r}
p = c(1,1,1)
lr = 0.01
for (i in 1:1000) {
  if (i == 1 | i %% 100 == 0)
    print(c(i, p, nll(p, x, y)))
  grad_est <- grad(func = function(p) nll(p, x, y), x = p)
  p = p - lr * grad_est
}
print(p)
```


