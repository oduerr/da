[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "da_website",
    "section": "",
    "text": "This is a collection of bits and pieces useful in connection with data analysis."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "Stan_Primer_Full.html",
    "href": "Stan_Primer_Full.html",
    "title": "Stan primer",
    "section": "",
    "text": "MCMC with Stan / Simple diagnostics"
  },
  {
    "objectID": "Stan_Primer_Full.html#stan",
    "href": "Stan_Primer_Full.html#stan",
    "title": "Stan primer",
    "section": "Stan",
    "text": "Stan\n\n\nCode\nlibrary(rstan)\noptions(mc.cores = parallel::detectCores())\nrstan_options(javascript=FALSE) #Prevents freezes of RStudio (Jan 2023) \n\nm_rstan = stan_model(model_code = stan_code) #Compiling from string\nm_rstan = stan_model(file='mymodel.stan') #Compiling from file\ns_rstan = sampling(m_rstan, data=data) #Sampling from file\n\n#No MCMC just evaluating parameters\nsampling(model_1, data=dat, algorithm=\"Fixed_param\", chain=1, iter=1)"
  },
  {
    "objectID": "Stan_Primer_Full.html#cmdstan",
    "href": "Stan_Primer_Full.html#cmdstan",
    "title": "Stan primer",
    "section": "Cmdstan",
    "text": "Cmdstan\n\n\nCode\nlibrary(cmdstanr)\nm_rcmdstan <- cmdstan_model(file_stan)\ns_rcmdstan = m_rcmdstan$sample(data = data)\n\n\n\nTidy Bayes\nWorks with rstan and cmdstanr\n\n\nCode\nlibrary(tidybayes)\nspread_draws(s, c(a,b)) #Extracts a and b from s (stan or cmdstan samples)\nspread_draws(s, f[i])  #Extracts vector f and calls components i\n\n\n\n\nBayes plot\nWorks with rstan and cmdstanr\n\n\nCode\n  s = s_rcmdstan$draws() #We need to call draws() 2023\n  bayesplot::mcmc_trace(s)\n\n\n\n\nRStudio\nSometimes R gets slow when dealing with stan. At least in my case\nrstan_options(javascript=FALSE)"
  },
  {
    "objectID": "Stan_Primer_Full.html#other-cheat-sheets",
    "href": "Stan_Primer_Full.html#other-cheat-sheets",
    "title": "Stan primer",
    "section": "Other Cheat Sheets",
    "text": "Other Cheat Sheets\n\nhttp://www.sumsar.net/files/posts/2017-bayesian-tutorial-exercises/stan_cheat_sheet2.12.pdf\nhttps://github.com/sieste/Stan_cheatsheet"
  },
  {
    "objectID": "Stan_Primer_Full.html#data-used",
    "href": "Stan_Primer_Full.html#data-used",
    "title": "Stan primer",
    "section": "Data used",
    "text": "Data used\nSome Data for linear regression\n\n\nCode\nN = 4\nx = c(-2.,-0.66666, 0.666, 2.)\ny = c(-6.25027354, -2.50213382, -6.07525495,  7.92081243)\ndata = list(N=N, x=x, y=y)"
  },
  {
    "objectID": "Stan_Primer_Full.html#getting-samples-from-the-posterior",
    "href": "Stan_Primer_Full.html#getting-samples-from-the-posterior",
    "title": "Stan primer",
    "section": "Getting samples from the posterior",
    "text": "Getting samples from the posterior\nThere are currently (2023) two interfaces to stan from R. RStan (https://mc-stan.org/users/interfaces/rstan) which is a bit slower and does not use the latest stan compiler and rcmdstan (https://mc-stan.org/cmdstanr/articles/cmdstanr.html).\n\nThe technical steps\nThere are 3 steps:\n\nDefining the model\nCompiling the model. In this step C code is generated.\nRunning the simulation / sampling from the posterior\nExtracting the samples from the posterior\n\n\n\nDefinition\nTo define a model, you can add a string or create a .stan file. Another option is to use a Stan markdown chunk and output.var=my_model to the name of the model. Code completion and highlighting is working for files and code chunks.\n\n\nCode\nstan_code = \"data{\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\n\nparameters{\n  real a; //Instead of using e.g. half Gaussian\n  real b;\n  real<lower=0> sigma;\n}\n\nmodel{\n  //y ~ normal(mu, sigma);\n  y ~ normal(a * x + b, sigma);\n  a ~ normal(3, 10); \n  b ~ normal(0, 10); \n  sigma ~ normal(0,10);\n}\"\n\n\n\n\nCompiling\nCompiling works with:\n\nCompiling rstan stan_model(model_code = stan_code) or stan_model(file='mymodel.stan')\nCompiling cmdstan cmdstan_model(file_stan)\n\n\nCompiling with rstan\n\n\nCode\n  library(rstan)\n  m_rstan = stan_model(model_code = stan_code)\n\n\nTrying to compile a simple C file\n\n\n\n\nCompiling with rcmdstan\nThere is no possibility to use a string for cmd_stan.\n\n\nCode\n  m_rcmdstan <- cmdstan_model(stan_file='stan/simple_lr.stan')\n\n\n\n\n\nSampling / running the chains\nFor rstan: sampling(m_rstan, data=data) For cmdstan: mod$sample(data = data_file, seed=123)\n\n\nCode\n  s_rcmdstan = m_rcmdstan$sample(data = data)\n\n\n\n\nCode\n  s_rstan = sampling(m_rstan)  \n\n\n\n\nDiagnostics of the chains\nThe package bayesplot can handle both interfaces\n\nTrace\n\n\nCode\n#traceplot(s_rstan, 'a')\n#bayesplot::mcmc_trace(s_rstan)\nbayesplot::mcmc_trace(s_rcmdstan$draws()) #similar result\n\n\n\n\n\nCode\ns_rstan\n\n\nInference for Stan model: 4bc92a844d593bcbe180a8a2fc11ffa0.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n       mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat\na      2.89    0.07 2.60  -2.88  1.54  2.92  4.35  8.43  1532 1.00\nb     -1.54    0.09 3.78  -9.13 -3.63 -1.60  0.51  6.22  1969 1.00\nsigma  7.44    0.10 3.54   2.98  4.80  6.73  9.19 16.53  1359 1.00\nlp__  -8.01    0.05 1.54 -11.88 -8.74 -7.67 -6.88 -6.17   921 1.01\n\nSamples were drawn using NUTS(diag_e) at Thu Jan  5 10:45:31 2023.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nCode\n# Rhat close to one and n_eff lager than half the number of draws; look fine\n\n\nKey Numbers\n\nRhat is something like the ratio of variation between the chains to withing the chains\nn_eff number of effective samples taking the autocorrelation into account (in cmd_stan the output is ess_bulk and ess_tail)\n\n\n\nShiny Stan\n\n\nCode\n  #Shiny Stan, quite overwhelming\n  library(shinystan)\n  launch_shinystan(samples)\n\n\n\n\n\nPosteriors (of the parameters)\nGetting the samples can be done as\n\nRstan extract(s_rstan)\ncmdstan s_rcmdstan$draws()\n\nAnother handy package is tidybayes which can handle the output of rstan and rcmdstan\n\n\nCode\nlibrary(tidybayes)\nhead(spread_draws(s_rcmdstan, c(a,b))) #Non-tidy a and b in one row\n\n\n# A tibble: 6 × 5\n  .chain .iteration .draw     a      b\n   <int>      <int> <int> <dbl>  <dbl>\n1      1          1     1  8.40  2.75 \n2      1          2     2  7.80 -2.02 \n3      1          3     3  4.81  1.03 \n4      1          4     4  5.51 -0.776\n5      1          5     5  2.88 -2.62 \n6      1          6     6  2.83 -2.07 \n\n\nCode\nhead(gather_draws(s_rstan, c(a,b))) #The ggplot like syntax\n\n\n# A tibble: 6 × 5\n# Groups:   .variable [1]\n  .chain .iteration .draw .variable  .value\n   <int>      <int> <int> <chr>       <dbl>\n1      1          1     1 a          0.624 \n2      1          2     2 a          0.951 \n3      1          3     3 a          1.06  \n4      1          4     4 a         -1.16  \n5      1          5     5 a         -0.0412\n6      1          6     6 a          0.121 \n\n\nCode\n#spread_draws(model_weight_sex, a[sex]) for multilevel models\n\n\n\nStan functions\n\n\nCode\n  #plot(samples)\n  #samples = extract(s_rstan)\n  stan_dens(s_rstan)\n\n\n\n\n\nCode\n  #Note that these are marginals!\n\n\n\n\n“Manually” visualize the posterior\nWe extract samples from the posterior via extract (in some installation the wrong extract function is taken in that case use rstan::extract to use the right one). Visualize the posterior distribution of \\(a\\) from the samples.\n\n\nCode\n# Extract samples\npost = rstan::extract(s_rstan)\nT = length(post$a)\nhist(post$a,100, freq=F)\nlines(density(post$a),col='red')  \n\n\n\n\n\n\n\nPairs plot\nUsing the pairs plot, correlations in the variables can be found.\n\n\nCode\nnp_cp = bayesplot::nuts_params(s_rstan)\nbayesplot::mcmc_pairs(s_rstan, np = np_cp,pars = c(\"a\",\"b\"))\n\n\n\n\n\n\n\n\nPosterior Predictive Plots\n\n\nTask: Use the samples to create the following posterior predictive plots\nSome background first: posterior predictive distribution: \\[\n  p(y|x, D) =  \\int p(y|x,\\theta) p(\\theta|D) \\; d\\theta\n\\] Instead of integration, we sample in two turns\n\n\\(\\theta_i \\sim p(\\theta|D)\\)\n\\(y_{ix} \\sim p(y|x,\\theta_i)\\) #We do this for many x in practice\n\n\nCreation of the posterior predictive samples by hand\nYou can either do this part, or use stan to create the posterior predictive samples \\(y_{ix}\\) from the samples \\(\\theta_i\\) by hand.\nTip: Create two matrices yix and muix from the posterior samples of \\(a,b,\\sigma\\) with dimension (rows = number of posterior samples and cols = number of x positions).\n\n\nCode\nxs = -10:15 # The x-range 17 values from -1 to 15\nM = length(xs) \nyix = matrix(nrow=T, ncol = M) #Matrix from samples (number of posterior draws vs number of xs)\nmuix = matrix(nrow=T, ncol = M) #Matrix from mu (number of posterior draws vs number of xs)\nfor (i in 1:T){ #Samples from the posterior\n  a = post$a[i] #Corresponds to samples from theta\n  b = post$b[i]\n  sigma = post$sigma[i]\n  for (j in 1:M){ #Different values of X\n    mu = a * xs[j] + b\n    muix[i,j] = a * xs[j] + b\n    yix[i,j] = rnorm(1, mu, sigma) # Single number drawn\n  }\n}\n\nif (FALSE){\n  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='mu=a*x+b')\n  for (i in 1:100){\n    lines(xs, muix[i,],lwd=0.25,col='blue')\n  }\n  \n  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='ys')\n  for (i in 1:100){\n    points(xs, yix[i,], pch='.',col='red')\n  }\n}\n\n\nAfter you created the matrices yix and muix you can use the following function to draw the lines for the quantiles.\n\n\nCode\nplot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='quantiles (y and mu)')\nquant_lines = function(x2, y_pred, col='blue'){\n  m = apply(y_pred, 2,quantile, probs=c(0.50))\n  lines(x2, m,col=col)\n  q05 = apply(y_pred, 2, quantile, probs=c(0.25))\n  q95 = apply(y_pred, 2, quantile, probs=c(0.75))\n  lines(x2, q05,col=col)\n  lines(x2, q95,col=col)  \n}\n\nquant_lines(xs,yix, col='red')\nquant_lines(xs,muix, col='blue')\n\n\n\n\n\n\n\nCreation of the posterior predictive samples with Stan\nIt’s also possible to draw posterior predictive samples. One can use the generated quantities code block for that.\ndata{\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n  //For the prediced distribution (new)\n  int<lower=0> N2;\n  vector[N2] x2;\n}\n\ngenerated quantities {\n  real Y_predict[N2]; \n  for (i in 1:N2){\n    Y_predict = normal_rng(a * x2 + b, sigma);\n  }\n}\n\n\nCode\n  x2 = -10:15\n  N2 = length(x2)\n  fit2 = rstan::stan(file = '~/Dropbox/__HTWG/DataAnalytics/_Current/lab/06_03_Bayes_3/Stan_Primer_model_pred.stan',\n                         data=list(N=N,x=x, y=y, N2=N2,x2=x2),iter=10000)\n\n\n\n\nCode\n  d2 = rstan::extract(fit2)\n  y_pred = d2$Y_predict\n  dim(y_pred)\n  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='quantiles (y and mu)')\n  quant_lines(x2,y_pred, col='red')"
  }
]