---
output:
  pdf_document:
    highlight: pygments
    includes:
---

```{r, echo=FALSE, eval=TRUE, message=FALSE}
  if (exists("lsg") == FALSE){ #Nur falls von RStudio aufgerufen
    lsg <- TRUE   #Wenn man die lsg ausgeben will dann lsg <- TRUE sonst 
  }
  if (exists("baseDir") == FALSE){ #Nur falls von RStudio aufgerufen
    baseDir = getwd()
  }
  ig <- function(name, scale = 1) {
     return (paste0("\\includegraphics[ scale =", scale,"]{", baseDir,"/", name, "}"))
  }
```

## MCMC with Stan / Simple diagnostics

The following lab/exercise should guide you to work with stan. We implement Bayesian linear regression. Work on the parts that are marked with "Task".

You might find the following resources sheets helpful.

### Cheat Sheets

-   <http://www.sumsar.net/files/posts/2017-bayesian-tutorial-exercises/stan_cheat_sheet2.12.pdf>
-   <https://github.com/sieste/Stan_cheatsheet>
-   <https://oduerr.github.io/da/Stan_Primer_Full.html>


### Data

Some Data for linear regression

```{r }
N = 4
x = c(-2.,-0.66666, 0.666, 2.)
y = c(-6.25027354, -2.50213382, -6.07525495,  7.92081243)
plot(x,y)
```

### Definition of a model

To define a model, you can add a string or create a `.stan` file. 

#### Task: Compiling and sampling.

Try to understand the following model and compile it. The model can be found at https://github.com/oduerr/da/blob/master/lab/lr_mcmc_diag/linear_regression.stan


```{r, warning=FALSE,message=FALSE, eval=FALSE,echo=TRUE}
stan_code = "data{
  int<lower=0> N;
  vector[N] y;
  vector[N] x;
}

parameters{
  real a; //Instead of using e.g. half Gaussian
  real b;
  real<lower=0> sigma;
}

model{
  //y ~ normal(mu, sigma);
  y ~ normal(a * x + b, sigma);
  a ~ normal(3, 10); 
  b ~ normal(0, 10); 
  sigma ~ normal(0,10);
}"
```

Once the model is compiled the sampling is done. You can also compile and sample via

```{r echo=TRUE, eval=FALSE, warning=FALSE, results="hide"}
  library(cmdstanr)
  m_rcmdstan <- cmdstan_model('~/Documents/GitHub/da/lab/lr_mcmc_diag/linear_regression.stan') #Compiling
  samples = m_rcmdstan$sample(data=list(N=N,x=x, y=y))
```

### Diagnostics of the chains

#### Task: Trace plot `Rhat` and `n_eff`

Inspect the traceplot, do they look good?

```{r bayesplot}
bayesplot::mcmc_trace(samples$draws())
```

```{r, eval=lsg, echo=lsg}
# They rapidly jump over all values. All chains are similar. The Hairy Capatiller
```

#### Key Numbers

-   `Rhat` is something like the ratio of variation between the chains to withing the chains
-   `n_eff` number of effective samples taking the autocorrelation into account

```{r}
  samples
```

```{r, eval=lsg, echo=lsg}
# Rhat close to one and n_eff lager than half the number of draws; look fine
```

```{r, eval=FALSE, echo=FALSE}
  #Shiny Stan, quite overwhelming
  #library(shinystan)
  #launch_shinystan(samples)
```

### Posteriors (of the parameters)


#### Task: "Manually" visualize the posterior

Visualize the posterior distribution of $a,b$ and $a$ from the samples. Note that this are the marginals.

```{r echo=lsg, eval=TRUE}
# Extract samples
post = samples$draws(format = 'df') #Sampling
if (lsg){ #Only show plots in the solution
  library(tidyverse)
  ggplot(post, aes(x=a, y=b)) + geom_point(size=0.1) + geom_density_2d() 
  hist(post$a,100, freq=F)
  lines(density(post$a),col='red')  
}
```

### Posterior Predictive Plots

#### Task: Use the samples to create the following posterior predictive plots

Some background first: posterior predictive distribution: $$
  p(y|x, D) =  \int p(y|x,\theta) p(\theta|D) \; d\theta
$$ Instead of integration, we sample in two turns

-   $\theta_i \sim p(\theta|D)$
-   $y_{ix} \sim p(y|x,\theta_i)$ #We do this for many x in practice

#### Creation of the posterior predictive samples by hand

You can either do this part, or use stan to create the posterior predictive samples $y_{ix}$ from the samples $\theta_i$ by hand.

Tip: Create two matrices `yix` and `muix` from the posterior samples of $a,b,\sigma$ with dimension (rows = number of posterior samples and cols = number of x positions).

```{r echo=lsg, eval=TRUE}
T = nrow(post)
xs = -10:15 # The x-range 17 values from -1 to 15
M = length(xs) 
yix = matrix(nrow=T, ncol = M) #Matrix from samples (number of posterior draws vs number of xs)
muix = matrix(nrow=T, ncol = M) #Matrix from mu (number of posterior draws vs number of xs)
for (i in 1:T){ #Samples from the posterior
  a = post$a[i] #Corresponds to samples from theta
  b = post$b[i]
  sigma = post$sigma[i]
  for (j in 1:M){ #Different values of X
    mu = a * xs[j] + b
    muix[i,j] = a * xs[j] + b
    yix[i,j] = rnorm(1, mu, sigma) # Single number drawn
  }
}

if (TRUE){
  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='mu=a*x+b')
  for (i in 1:100){
    lines(xs, muix[i,],lwd=0.25,col='blue')
  }
  
  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='ys')
  for (i in 1:100){
    points(xs, yix[i,], pch='.',col='red')
  }
}
```

After you created the matrices `yix` and `muix` you can use the following function to draw the lines for the quantiles.

```{r}
plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='quantiles (y and mu)')
quant_lines = function(x2, y_pred, col='blue'){
  m = apply(y_pred, 2,quantile, probs=c(0.50))
  lines(x2, m,col=col)
  q05 = apply(y_pred, 2, quantile, probs=c(0.25))
  q95 = apply(y_pred, 2, quantile, probs=c(0.75))
  lines(x2, q05,col=col)
  lines(x2, q95,col=col)  
}

quant_lines(xs,yix, col='red')
quant_lines(xs,muix, col='blue')
```

#### Creation of the posterior predictive samples with Stan

It's also possible to draw posterior predictive samples. One can use the `generated quantities` code block for that.

    data{
      int<lower=0> N;
      vector[N] y;
      vector[N] x;
      //For the prediced distribution (new)
      int<lower=0> N2;
      vector[N2] x2;
    }

    generated quantities {
      real Y_predict[N2]; 
      for (i in 1:N2){
        Y_predict = normal_rng(a * x2 + b, sigma);
      }
    }

```{r, results='hide'}
  x2 = -10:15
  N2 = length(x2)
  m2 <- cmdstan_model('~/Documents/GitHub/da/lab/lr_mcmc_diag/Stan_Primer_model_pred.stan') #Compiling
  fit2 = m2$sample(data=list(N=N,x=x, y=y, N2=N2,x2=x2))
```

```{r}
  y_pred = fit2$draws('Y_predict', format = 'df')[,1:26] #Only the ones starting with predicts
  dim(y_pred)
  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='quantiles (y and mu)')
  quant_lines(x2,y_pred, col='red')
```
