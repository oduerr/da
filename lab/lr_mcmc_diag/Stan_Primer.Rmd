---
output:
  pdf_document:
    highlight: pygments
    includes:
---

```{r, echo=FALSE, eval=TRUE, message=FALSE}
  if (exists("lsg") == FALSE){ #Nur falls von RStudio aufgerufen
    lsg <- TRUE   #Wenn man die lsg ausgeben will dann lsg <- TRUE sonst 
  }
  if (exists("baseDir") == FALSE){ #Nur falls von RStudio aufgerufen
    baseDir = getwd()
  }
  ig <- function(name, scale = 1) {
     return (paste0("\\includegraphics[ scale =", scale,"]{", baseDir,"/", name, "}"))
  }
```

## MCMC with Stan / Simple diagnostics

The following lab/exercise should guide you to work with stan. We implement Bayesian linear regression, 
the focus is on the diagnostics of the chains. Work on the parts that are marked with "Task".

You might find the following resources sheets helpful.

### Cheat Sheets

-   <http://www.sumsar.net/files/posts/2017-bayesian-tutorial-exercises/stan_cheat_sheet2.12.pdf>
-   <https://github.com/sieste/Stan_cheatsheet>
-   <https://oduerr.github.io/da/Stan_Primer_Full.html>


### Data

Some Data for linear regression

```{r }
N = 4
x = c(-2.,-0.66666, 0.666, 2.)
y = c(-6.25027354, -2.50213382, -6.07525495,  7.92081243)
plot(x,y)
```

### Definition of a model

To define a model, you can add a string or create a `.stan` file. 

#### Task: Compiling and sampling.

Try to understand the following model and compile it. The model can be found at https://github.com/oduerr/da/blob/master/lab/lr_mcmc_diag/linear_regression.stan


```{r, echo=lsg, eval=FALSE, code=readLines("/Users/oli/Documents/GitHub/da/lab/lr_mcmc_diag/linear_regression.stan"), collapse=TRUE}
1
```

Once the model is compiled the sampling is done. You can also compile and sample via

```{r echo=TRUE, eval=lsg, warning=FALSE, results="hide"}
  library(cmdstanr)
  m_rcmdstan <- cmdstan_model('~/Documents/GitHub/da/lab/lr_mcmc_diag/linear_regression.stan') #Compiling
  samples = m_rcmdstan$sample(data=list(N=N,x=x, y=y))
```

### Diagnostics of the chains

#### Task: Trace plot `Rhat` and `n_eff`

Inspect the traceplot, do they look good?

```{r bayesplot, eval=lsg, echo=lsg}
bayesplot::mcmc_trace(samples$draws())
```

```{r, eval=FALSE, echo=FALSE}
# Just to make slides
library(bayesplot)
library(ggplot2)
samples = m_rcmdstan$sample(data=list(N=N,x=x, y=y), chains=1)
d = bayesplot::mcmc_trace(samples$draws('a'))
d + xlab('Iterations') + ylab('a')
ggsave('trace_a.pdf',width=10,height=5)
```

```{r, eval=lsg, echo=lsg}
# They rapidly jump over all values. All chains are similar. The Hairy Capatiller.
```

#### Key Numbers

-   `Rhat` is something like the ratio of variation between the chains to withing the chains
-   `n_eff` number of effective samples taking the autocorrelation into account

```{r samples_print, eval=lsg, echo=lsg}
  samples
```

```{r, eval=lsg, echo=lsg}
# Rhat close to one and n_eff lager than half the number of draws; look fine
```

```{r, eval=FALSE, echo=FALSE}
  #Shiny Stan, quite overwhelming
  #library(shinystan)
  #launch_shinystan(samples)
```

### Posteriors (of the parameters)


#### Task: "Manually" visualize the posterior

Visualize the posterior distribution of $a,b$ and $a$ from the samples. Note that this are the marginals.

```{r echo=lsg, eval=TRUE}
# Extract samples
post = samples$draws(format = 'df') #Sampling
if (lsg){ #Only show plots in the solution
  library(tidyverse)
  ggplot(post, aes(x=a, y=b)) + geom_point(size=0.1) + geom_density_2d() 
  hist(post$a,100, freq=F)
  lines(density(post$a),col='red')  
}
```
