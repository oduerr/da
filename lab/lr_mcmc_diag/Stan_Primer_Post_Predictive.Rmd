---
output:
  pdf_document:
    highlight: pygments
    includes:
---

```{r, echo=FALSE, eval=TRUE, message=FALSE}
  if (exists("lsg") == FALSE){ #Nur falls von RStudio aufgerufen
    lsg <- TRUE   #Wenn man die lsg ausgeben will dann lsg <- TRUE sonst 
  }
  if (exists("baseDir") == FALSE){ #Nur falls von RStudio aufgerufen
    baseDir = getwd()
  }
  ig <- function(name, scale = 1) {
     return (paste0("\\includegraphics[ scale =", scale,"]{", baseDir,"/", name, "}"))
  }
```

## Linear Regression Posterior Predictive

The following exercise shows posterior predictive plots for linear regression. 


### Data

Some Data for linear regression

```{r }
N = 4
x = c(-2.,-0.66666, 0.666, 2.)
y = c(-6.25027354, -2.50213382, -6.07525495,  7.92081243)
plot(x,y)
```

#### Model
Definition, we use a simple linear regression model. 


```{r, echo=lsg, eval=FALSE, code=readLines("/Users/oli/Documents/GitHub/da/lab/lr_mcmc_diag/linear_regression.stan"), collapse=TRUE}
1
```
```{r echo=TRUE, eval=lsg, warning=FALSE, results="hide"}
  library(cmdstanr)
  m_rcmdstan <- cmdstan_model('~/Documents/GitHub/da/lab/lr_mcmc_diag/linear_regression.stan') #Compiling
  samples = m_rcmdstan$sample(data=list(N=N,x=x, y=y))
```


```{r samples_print, eval=lsg, echo=lsg}
  samples
```

### Posteriors (of the parameters)


#### Task: "Manually" visualize the posterior
Visualize the posterior distribution of $a,b$ and $a$ from the samples. Note that this are the marginals.

```{r echo=lsg, eval=TRUE}
# Extract samples
post = samples$draws(format = 'df') #Sampling
if (lsg){ #Only show plots in the solution
  library(tidyverse)
  ggplot(post, aes(x=a, y=b)) + geom_point(size=0.1) + geom_density_2d() 
  hist(post$a,100, freq=F)
  lines(density(post$a),col='red')  
}
```

### Posterior Predictive Plots

#### Task: Use the samples to create the following posterior predictive plots

Some background first: posterior predictive distribution: $$
  p(y|x, D) =  \int p(y|x,\theta) p(\theta|D) \; d\theta
$$ Instead of integration, we sample in two turns

-   $\theta_i \sim p(\theta|D)$
-   $y_{ix} \sim p(y|x,\theta_i)$ #We do this for many x in practice

#### Creation of the posterior predictive samples by hand

You can either do this part, or use stan to create the posterior predictive samples $y_{ix}$ from the samples $\theta_i$ by hand.

Tip: Create two matrices `yix` and `muix` from the posterior samples of $a,b,\sigma$ with dimension (rows = number of posterior samples and cols = number of x positions).

```{r echo=lsg, eval=TRUE}
T = nrow(post)
xs = -10:15 # The x-range 17 values from -1 to 15
M = length(xs) 
yix = matrix(nrow=T, ncol = M) #Matrix from samples (number of posterior draws vs number of xs)
muix = matrix(nrow=T, ncol = M) #Matrix from mu (number of posterior draws vs number of xs)
for (i in 1:T){ #Samples from the posterior
  a = post$a[i] #Corresponds to samples from theta
  b = post$b[i]
  sigma = post$sigma[i]
  for (j in 1:M){ #Different values of X
    mu = a * xs[j] + b
    muix[i,j] = a * xs[j] + b
    yix[i,j] = rnorm(1, mu, sigma) # Single number drawn
  }
}

if (TRUE){
  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='mu=a*x+b')
  for (i in 1:100){
    lines(xs, muix[i,],lwd=0.25,col='blue')
  }
  
  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='ys')
  for (i in 1:100){
    points(xs, yix[i,], pch='.',col='red')
  }
}
```

After you created the matrices `yix` and `muix` you can use the following function to draw the lines for the quantiles.

```{r}
plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='quantiles (y and mu)')
quant_lines = function(x2, y_pred, col='blue'){
  m = apply(y_pred, 2,quantile, probs=c(0.50))
  lines(x2, m,col=col)
  q05 = apply(y_pred, 2, quantile, probs=c(0.25))
  q95 = apply(y_pred, 2, quantile, probs=c(0.75))
  lines(x2, q05,col=col)
  lines(x2, q95,col=col)  
}

quant_lines(xs,yix, col='red')
quant_lines(xs,muix, col='blue')
```

#### Creation of the posterior predictive samples with Stan

It's also possible to draw posterior predictive samples. One can use the `generated quantities` code block for that.

    data{
      int<lower=0> N;
      vector[N] y;
      vector[N] x;
      //For the prediced distribution (new)
      int<lower=0> N2;
      vector[N2] x2;
    }

    generated quantities {
      real Y_predict[N2]; 
      for (i in 1:N2){
        Y_predict = normal_rng(a * x2 + b, sigma);
      }
    }

```{r, results='hide'}
  x2 = -10:15
  N2 = length(x2)
  m2 <- cmdstan_model('~/Documents/GitHub/da/lab/lr_mcmc_diag/Stan_Primer_model_pred.stan') #Compiling
  fit2 = m2$sample(data=list(N=N,x=x, y=y, N2=N2,x2=x2))
```

```{r}
  y_pred = fit2$draws('Y_predict', format = 'df')[,1:26] #Only the ones starting with predicts
  dim(y_pred)
  plot(x, y, xlim=c(-10,15), ylim=c(-25,25), ylab='quantiles (y and mu)')
  quant_lines(x2,y_pred, col='red')
```
